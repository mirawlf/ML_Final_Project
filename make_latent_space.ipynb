{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from fitter import Fitter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATE DISTRIBUTIONS ARRAY\n",
    "\n",
    "pdfs = pickle.load(open(\"./distributions/pdfs.pickle\", \"rb\"))\n",
    "data = pd.read_csv('./full_data_with_nans.csv')\n",
    "col_names = np.array(data.keys())\n",
    "#ST STARTS AT 49\n",
    "st_cols = col_names[49:-2]\n",
    "\n",
    "bad_indices = []\n",
    "\n",
    "#THESE TWO ARE BAD IN GENERAL\n",
    "print(np.argwhere(st_cols=='ST8SV')[0][0])\n",
    "print(np.argwhere(st_cols=='ST68SV')[0][0])\n",
    "\n",
    "#THESE THREE ARE MIXTURE\n",
    "bad_indices.append(np.argwhere(st_cols=='ST21SV')[0][0])\n",
    "bad_indices.append(np.argwhere(st_cols=='ST80SV')[0][0])\n",
    "bad_indices.append(np.argwhere(st_cols=='ST153SV')[0][0])\n",
    "\n",
    "distributions = []\n",
    "\n",
    "mixture_params = []\n",
    "mixture_params.append( (-0.0033, 0.0006, 1.2/11.2, 0.0004, 0.0013, 10/11.2) )\n",
    "mixture_params.append( (-0.0026, 0.0004, 1.2/11.2, 0.00037, 0.001, 10/11.2) )\n",
    "mixture_params.append( (-5.352063451854405e-05, 2.9170065357038982e-06, 1.3/9.3, 8.993002770407149e-06, 8.263642179231052e-06, 8/9.3) )\n",
    "\n",
    "for pdf in pdfs:\n",
    "    distributions.append(pdf[1].get_best())\n",
    "\n",
    "for j, i in enumerate(bad_indices):\n",
    "    key = list(distributions[i].keys())[0]\n",
    "    distributions[i]['normal_mixture'] = distributions[i].pop(key)\n",
    "    distributions[i]['normal_mixture'] = mixture_params[j]\n",
    "    print(distributions[i])\n",
    "\n",
    "for i, pdf in enumerate(pdfs):\n",
    "    distributions[i]['st'] = st_cols[i]\n",
    "    \n",
    "print(len(distributions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATE LATENT SPACE\n",
    "#THIS ALSO PLOTS HISTOGRAMS AND DISTRIBUTIONS FROM LESHA'S PICKLE\n",
    "# 325 histograms\n",
    "\n",
    "import scipy.stats\n",
    "import numpy as np\n",
    "import numpy.random\n",
    "import scipy.stats as ss\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = pd.read_csv('./st_features_without_nans_and_y_with_nans.csv')\n",
    "latent_features = np.zeros((data.shape[0], data.shape[1]-1))\n",
    "latent_unified = np.zeros((data.shape[0], data.shape[1]-1))\n",
    "col_names = np.array(data.keys())\n",
    "st_cols = col_names[1:]\n",
    "\n",
    "for i in range(len(st_cols)):\n",
    "    current = data[st_cols[i]]\n",
    "    \n",
    "    mean = np.mean(current)\n",
    "    stdev = np.std(current)\n",
    "    current = (current - mean)/stdev**2\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.hist(current, bins = 100, density=True)\n",
    "\n",
    "    key = list(distributions[i].keys())[0]\n",
    "    if key == 'normal_mixture':\n",
    "        n = 10000\n",
    "        numpy.random.seed(0x5eed)\n",
    "        norm_params = np.array([[distributions[i][key][0],\n",
    "                                 distributions[i][key][1]],\n",
    "                                [distributions[i][key][3],\n",
    "                                 distributions[i][key][4]]])\n",
    "        weights = np.array([distributions[i][key][2],\n",
    "                            distributions[i][key][5]])\n",
    "        n_components = norm_params.shape[0]\n",
    "        mixture_idx = numpy.random.choice(len(weights), size=n, replace=True, p=weights)\n",
    "        y = numpy.fromiter((ss.norm.rvs(*(norm_params[i])) for i in mixture_idx),\n",
    "                           dtype=np.float64)\n",
    "        xs = np.linspace(y.min(), y.max(), 200)\n",
    "        ys = np.zeros_like(xs)\n",
    "\n",
    "        for (l, s), w in zip(norm_params, weights):\n",
    "            ys += ss.norm.pdf(xs, loc=l, scale=s) * w\n",
    "        plt.plot(xs, ys, lw=4)\n",
    "        for j in range(latent_features.shape[0]):\n",
    "            val = 0.0\n",
    "            for (l, s), w in zip(norm_params, weights):\n",
    "                val += ss.norm.cdf(current[j], loc=l, scale=s) * w\n",
    "            latent_features[j][i] = val\n",
    "            latent_unified[j][i] = scipy.stats.norm.ppf(latent_features[j][i], loc=0., scale=1.)\n",
    "    else:\n",
    "        dist = getattr(scipy.stats, key)(*distributions[i][key])\n",
    "        y = np.linspace(dist.ppf(0.01), dist.ppf(0.99))\n",
    "        plt.plot(y, dist.pdf(y), lw=4)\n",
    "        for j in range(latent_features.shape[0]):\n",
    "            latent_features[j][i] = dist.cdf(current[j])\n",
    "            latent_unified[j][i] = scipy.stats.norm.ppf(latent_features[j][i], loc=0., scale=1.)\n",
    "\n",
    "    plt.title(st_cols[i])\n",
    "    plt.savefig(\"./plots/\" + st_cols[i] + \".png\")\n",
    "    plt.close()\n",
    "    \n",
    "for i in range(len(st_cols)):\n",
    "    data[st_cols[i]] = latent_unified.T[i]\n",
    "    #print(data[st_cols[i]])\n",
    "print(data.shape)\n",
    "data.to_csv(\"latent_unified_with_nan_y_with_nan.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHECK IF DATA IS NOW STANDARD NORMAL\n",
    "#PLOT 325 HISTOGRAMS AND STANDARD NORMAL DISTRIBUTION\n",
    "\n",
    "#ST91CV ST91TA ARE BAD, THEY ADD INFS\n",
    "data_new = data.replace([np.inf, -np.inf], np.nan)\n",
    "data_new = data_new.dropna(subset=col_names)\n",
    "\n",
    "norm = scipy.stats.norm(loc = 0., scale=1.)\n",
    "z = np.linspace(norm.ppf(0.01), norm.ppf(0.99), col_names.shape[0])\n",
    "zz = norm.pdf(z)\n",
    "\n",
    "for i in range(1, col_names.shape[0]):\n",
    "    cur = data_new[col_names[i]]\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.hist(cur, bins=200, density = True)\n",
    "    plt.plot(z, zz, lw=4)\n",
    "    plt.title(col_names[i])\n",
    "    plt.savefig(\"./latent/\"+col_names[i]+\".png\")\n",
    "    \n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
